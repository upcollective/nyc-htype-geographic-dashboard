"""
Vulnerability data loading and processing utilities for Solara dashboard.
Provides STH (Students in Temporary Housing) and ENI (Economic Need Index) indicators.

Data Source: HTYPE PowerBI Export > Vulnerability_Indicators tab

Ported from Streamlit version - adapted for Solara (no streamlit dependency).
"""
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)

# Threshold for "high" designation
# STH ≥15% puts school in top ~30% for housing instability
# ENI ≥74% is DOE's own "skewed toward lower incomes" cutoff
HIGH_STH_THRESHOLD = 0.15  # 15% STH threshold
HIGH_ENI_THRESHOLD = 0.74  # 74% ENI threshold (DOE cutoff)

# Tab name for consolidated vulnerability data
VULNERABILITY_TAB = 'Vulnerability_Indicators'


def parse_percentage_string(value) -> Optional[float]:
    """
    Parse a percentage value that may be a string like '87.9%' or a decimal like 0.879.

    Google Sheets often returns formatted display values like '87.9%' via get_all_records().
    This function handles both raw decimals and formatted strings.

    Returns:
        Float in decimal form (0.0-1.0), or None if invalid
    """
    if pd.isna(value) or value == '' or value is None:
        return None

    # If already a number, check if it needs normalization
    if isinstance(value, (int, float)):
        num = float(value)
        # If > 1, assume it's a whole percentage (87.9 = 87.9%)
        return num / 100 if num > 1 else num

    # Handle string values
    str_val = str(value).strip()
    if not str_val:
        return None

    # Remove % sign if present
    if str_val.endswith('%'):
        str_val = str_val[:-1]

    try:
        num = float(str_val)
        # If > 1, it's a whole percentage (87.9 = 87.9%)
        return num / 100 if num > 1 else num
    except ValueError:
        return None


def load_vulnerability_data() -> pd.DataFrame:
    """
    Load consolidated vulnerability data from HTYPE PowerBI Export.

    The Vulnerability_Indicators tab contains pre-consolidated, normalized data:
    - Aligned to the authoritative 1,656 school DBN list
    - Percentages may be formatted as strings ('87.9%') - will be converted to decimals
    - Includes high_sth and high_eni flags

    Returns DataFrame with:
    - school_dbn: Primary key
    - school_name: School name
    - enrollment: Student enrollment count
    - economic_need_index: ENI as decimal (0.0-1.0)
    - sth_count: Students in temporary housing count
    - sth_percent: STH percentage as decimal (0.0-1.0)
    - high_sth: Boolean flag for high STH (>=15%)
    - high_eni: Boolean flag for high ENI (>=74%)
    """
    from .data_loader import load_from_google_sheets, GOOGLE_SHEET_ID

    try:
        df = load_from_google_sheets(
            sheet_id=GOOGLE_SHEET_ID,
            sheet_name=VULNERABILITY_TAB
        )
        logger.info(f"Loaded {len(df)} vulnerability records from {VULNERABILITY_TAB}")

        if len(df) == 0 or 'school_dbn' not in df.columns:
            logger.warning(f"{VULNERABILITY_TAB} tab is empty or malformed")
            return pd.DataFrame(columns=[
                'school_dbn', 'sth_count', 'sth_percent', 'economic_need_index'
            ])

    except Exception as e:
        logger.warning(f"Failed to load {VULNERABILITY_TAB}: {e}")
        return pd.DataFrame(columns=[
            'school_dbn', 'sth_count', 'sth_percent', 'economic_need_index'
        ])

    # Parse percentage columns
    pct_cols = ['sth_percent', 'economic_need_index']
    for col in pct_cols:
        if col in df.columns:
            df[col] = df[col].apply(parse_percentage_string)
            non_null = df[col].notna().sum()
            logger.info(f"Parsed {col}: {non_null} non-null values")

    # Ensure other numeric types
    other_numeric_cols = ['enrollment', 'sth_count']
    for col in other_numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    # Parse boolean columns (may be strings like 'TRUE'/'FALSE')
    bool_cols = ['high_sth', 'high_eni']
    for col in bool_cols:
        if col in df.columns:
            df[col] = df[col].apply(lambda x: str(x).upper() == 'TRUE' if pd.notna(x) else False)

    return df


def merge_vulnerability_with_training(
    training_df: pd.DataFrame,
    vulnerability_df: pd.DataFrame
) -> pd.DataFrame:
    """
    Merge vulnerability data with training status data.

    Args:
        training_df: School training status DataFrame (must have 'school_dbn')
        vulnerability_df: Vulnerability data DataFrame

    Returns:
        Merged DataFrame with STH and ENI columns added
    """
    # Select columns to merge
    merge_cols = ['school_dbn']
    optional_cols = ['sth_percent', 'sth_count', 'economic_need_index', 'enrollment']
    for col in optional_cols:
        if col in vulnerability_df.columns:
            merge_cols.append(col)

    merged = pd.merge(
        training_df,
        vulnerability_df[merge_cols],
        on='school_dbn',
        how='left'
    )

    # Add flag columns for high STH and high ENI (if not already present)
    if 'sth_percent' in merged.columns and 'high_sth' not in merged.columns:
        merged['high_sth'] = merged['sth_percent'] >= HIGH_STH_THRESHOLD

    if 'economic_need_index' in merged.columns and 'high_eni' not in merged.columns:
        merged['high_eni'] = merged['economic_need_index'] >= HIGH_ENI_THRESHOLD

    return merged


def calculate_vulnerability_stats(df: pd.DataFrame) -> dict:
    """
    Calculate summary statistics for vulnerability indicators.

    Args:
        df: DataFrame with vulnerability columns

    Returns:
        Dictionary of statistics
    """
    stats = {
        'total_schools': len(df),
    }

    # STH statistics
    if 'sth_percent' in df.columns:
        sth_data = df['sth_percent'].dropna()
        stats['schools_with_sth_data'] = len(sth_data)
        stats['avg_sth_percent'] = sth_data.mean() if len(sth_data) > 0 else None
        stats['max_sth_percent'] = sth_data.max() if len(sth_data) > 0 else None
        stats['high_sth_count'] = (df['sth_percent'] >= HIGH_STH_THRESHOLD).sum()

    # ENI statistics
    if 'economic_need_index' in df.columns:
        eni_data = df['economic_need_index'].dropna()
        stats['schools_with_eni_data'] = len(eni_data)
        stats['avg_eni'] = eni_data.mean() if len(eni_data) > 0 else None
        stats['max_eni'] = eni_data.max() if len(eni_data) > 0 else None
        stats['high_eni_count'] = (df['economic_need_index'] >= HIGH_ENI_THRESHOLD).sum()

    return stats


def get_sth_color(sth_percent: Optional[float]) -> str:
    """
    Get hex color for STH percentage visualization.
    Gradient from green (low) to red (high STH).

    Thresholds aligned to HIGH_STH_THRESHOLD (15%):
    - High: ≥15% (top ~30% of schools)
    - Elevated: 10-15%
    - Moderate: 5-10%
    - Low: <5%

    Returns hex color string.
    """
    if sth_percent is None or pd.isna(sth_percent):
        return '#808080'  # Gray for unknown

    # Clamp to 0-1
    sth = max(0, min(1, sth_percent))

    # Color gradient based on STH severity (aligned to 15% threshold)
    if sth < 0.05:
        return '#64a078'  # Low - sage green
    elif sth < 0.10:
        return '#b4b464'  # Moderate - yellow
    elif sth < 0.15:
        return '#c89650'  # Elevated - amber
    else:
        return '#b46464'  # High (≥15%) - coral/red


def get_sth_tier(sth_percent: Optional[float]) -> str:
    """Categorize STH percentage into tiers (aligned to 15% HIGH_STH_THRESHOLD)."""
    if sth_percent is None or pd.isna(sth_percent):
        return "Unknown"
    if sth_percent >= 0.15:
        return "High (15%+)"
    elif sth_percent >= 0.10:
        return "Elevated (10-15%)"
    elif sth_percent >= 0.05:
        return "Moderate (5-10%)"
    else:
        return "Low (<5%)"


# ============================================================================
# CRIME & SHELTER RISK INDICATOR LOADING
# ============================================================================

# Tab names for new risk indicator tables (to be added to PowerBI Export)
CRIME_BY_PRECINCT_TAB = 'Crime_By_Precinct'
SHELTER_BY_CD_TAB = 'Shelter_By_CD'


def load_crime_by_precinct() -> pd.DataFrame:
    """
    Load crime statistics aggregated by police precinct.

    Data includes HTYPE-relevant offenses from NYPD Complaint data:
    - trafficking_count: Explicit SEX TRAFFICKING offenses
    - htype_relevant_count: Broader category (child endangerment, sexual abuse, rape, prostitution)
    - Individual offense counts: child_endanger, sexual_abuse, rape, prostitution

    Data Source Priority:
    1. Google Sheets tab (Crime_By_Precinct) - for production
    2. Local CSV file (outputs/risk-indicator-tables/crime_by_precinct.csv) - for development

    Returns:
        DataFrame with precinct-level crime aggregates
    """
    from .data_loader import load_from_google_sheets, GOOGLE_SHEET_ID

    # Try Google Sheets first (production path)
    try:
        df = load_from_google_sheets(
            sheet_id=GOOGLE_SHEET_ID,
            sheet_name=CRIME_BY_PRECINCT_TAB
        )
        if len(df) > 0:
            logger.info(f"Loaded {len(df)} precinct crime records from Google Sheets")
            return _process_crime_data(df)
    except Exception as e:
        logger.debug(f"Google Sheets crime data not available: {e}")

    # Fall back to local CSV (development path)
    local_path = Path(__file__).parent.parent.parent.parent / 'risk-indicator-tables' / 'crime_by_precinct.csv'
    if local_path.exists():
        df = pd.read_csv(local_path)
        logger.info(f"Loaded {len(df)} precinct crime records from local CSV")
        return _process_crime_data(df)

    logger.warning("Crime data not available from Google Sheets or local CSV")
    return pd.DataFrame(columns=['precinct', 'trafficking_count', 'htype_relevant_count'])


def _process_crime_data(df: pd.DataFrame) -> pd.DataFrame:
    """Process and validate crime data."""
    # Ensure precinct is string for joining
    if 'precinct' in df.columns:
        df['precinct'] = df['precinct'].astype(str).str.strip()

    # Ensure numeric columns
    numeric_cols = ['trafficking_count', 'htype_relevant_count', 'child_endanger_count',
                    'sexual_abuse_count', 'rape_count', 'prostitution_count', 'total_complaints']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

    return df


def load_shelter_by_cd() -> pd.DataFrame:
    """
    Load shelter statistics aggregated by community district.

    Data from DHS (Department of Homeless Services):
    - shelter_cases: Number of family shelter cases
    - shelter_individuals: Total individuals in shelter

    Community District format: 3-digit BoroCD (e.g., "103" = Manhattan CD 3)

    Data Source Priority:
    1. Google Sheets tab (Shelter_By_CD) - for production
    2. Local CSV file (outputs/risk-indicator-tables/shelter_by_cd.csv) - for development

    Returns:
        DataFrame with community district-level shelter aggregates
    """
    from .data_loader import load_from_google_sheets, GOOGLE_SHEET_ID

    # Try Google Sheets first (production path)
    try:
        df = load_from_google_sheets(
            sheet_id=GOOGLE_SHEET_ID,
            sheet_name=SHELTER_BY_CD_TAB
        )
        if len(df) > 0:
            logger.info(f"Loaded {len(df)} community district shelter records from Google Sheets")
            return _process_shelter_data(df)
    except Exception as e:
        logger.debug(f"Google Sheets shelter data not available: {e}")

    # Fall back to local CSV (development path)
    local_path = Path(__file__).parent.parent.parent.parent / 'risk-indicator-tables' / 'shelter_by_cd.csv'
    if local_path.exists():
        df = pd.read_csv(local_path)
        logger.info(f"Loaded {len(df)} community district shelter records from local CSV")
        return _process_shelter_data(df)

    logger.warning("Shelter data not available from Google Sheets or local CSV")
    return pd.DataFrame(columns=['community_district', 'borough', 'shelter_cases', 'shelter_individuals'])


def _process_shelter_data(df: pd.DataFrame) -> pd.DataFrame:
    """Process and validate shelter data."""
    # Ensure community_district is string for joining
    if 'community_district' in df.columns:
        df['community_district'] = df['community_district'].astype(str).str.strip()

    # Ensure numeric columns
    numeric_cols = ['shelter_cases', 'shelter_individuals']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

    return df


def merge_crime_data_with_schools(
    school_df: pd.DataFrame,
    crime_df: pd.DataFrame
) -> pd.DataFrame:
    """
    Merge crime statistics with school data via police_precinct.

    Args:
        school_df: School data (must have 'police_precinct' column from Vulnerability_Indicators)
        crime_df: Crime data by precinct

    Returns:
        School DataFrame with crime columns added
    """
    if 'police_precinct' not in school_df.columns:
        logger.warning("police_precinct column not found in school data - cannot merge crime data")
        return school_df

    if len(crime_df) == 0:
        logger.warning("Crime data is empty - skipping merge")
        return school_df

    # Ensure join keys are same type (string)
    school_df = school_df.copy()
    school_df['police_precinct'] = school_df['police_precinct'].astype(str).str.strip()
    crime_df = crime_df.copy()
    crime_df['precinct'] = crime_df['precinct'].astype(str).str.strip()

    # Select columns to merge
    merge_cols = ['precinct']
    crime_cols = ['trafficking_count', 'htype_relevant_count', 'child_endanger_count',
                  'sexual_abuse_count', 'rape_count', 'prostitution_count']
    for col in crime_cols:
        if col in crime_df.columns:
            merge_cols.append(col)

    merged = pd.merge(
        school_df,
        crime_df[merge_cols],
        left_on='police_precinct',
        right_on='precinct',
        how='left'
    )

    # Drop redundant precinct column
    if 'precinct' in merged.columns:
        merged = merged.drop(columns=['precinct'])

    matched = merged['htype_relevant_count'].notna().sum() if 'htype_relevant_count' in merged.columns else 0
    logger.info(f"Merged crime data: {matched}/{len(merged)} schools matched to precincts")

    return merged


def merge_shelter_data_with_schools(
    school_df: pd.DataFrame,
    shelter_df: pd.DataFrame
) -> pd.DataFrame:
    """
    Merge shelter statistics with school data via community_district.

    Args:
        school_df: School data (must have 'community_district' column from Vulnerability_Indicators)
        shelter_df: Shelter data by community district

    Returns:
        School DataFrame with shelter columns added
    """
    if 'community_district' not in school_df.columns:
        logger.warning("community_district column not found in school data - cannot merge shelter data")
        return school_df

    if len(shelter_df) == 0:
        logger.warning("Shelter data is empty - skipping merge")
        return school_df

    # Ensure join keys are same type (string)
    school_df = school_df.copy()
    school_df['community_district'] = school_df['community_district'].astype(str).str.strip()
    shelter_df = shelter_df.copy()
    shelter_df['community_district'] = shelter_df['community_district'].astype(str).str.strip()

    # Select columns to merge (avoid duplicate community_district)
    merge_cols = ['community_district', 'shelter_cases', 'shelter_individuals']
    available_cols = [c for c in merge_cols if c in shelter_df.columns]

    merged = pd.merge(
        school_df,
        shelter_df[available_cols],
        on='community_district',
        how='left'
    )

    matched = merged['shelter_cases'].notna().sum() if 'shelter_cases' in merged.columns else 0
    logger.info(f"Merged shelter data: {matched}/{len(merged)} schools matched to community districts")

    return merged


def get_crime_tier(htype_relevant_count: Optional[int]) -> str:
    """
    Categorize precinct crime count into tiers for visualization.

    Thresholds based on distribution of 78 precincts:
    - High: >200 HTYPE-relevant offenses
    - Elevated: 100-200
    - Moderate: 50-100
    - Low: <50
    """
    if htype_relevant_count is None or pd.isna(htype_relevant_count):
        return "Unknown"

    count = int(htype_relevant_count)
    if count >= 200:
        return "High (200+)"
    elif count >= 100:
        return "Elevated (100-200)"
    elif count >= 50:
        return "Moderate (50-100)"
    else:
        return "Low (<50)"


def get_shelter_tier(shelter_individuals: Optional[int]) -> str:
    """
    Categorize community district shelter count into tiers for visualization.

    Thresholds based on distribution of 59 community districts:
    - High: >1500 individuals in shelter
    - Elevated: 750-1500
    - Moderate: 300-750
    - Low: <300
    """
    if shelter_individuals is None or pd.isna(shelter_individuals):
        return "Unknown"

    count = int(shelter_individuals)
    if count >= 1500:
        return "High (1500+)"
    elif count >= 750:
        return "Elevated (750-1500)"
    elif count >= 300:
        return "Moderate (300-750)"
    else:
        return "Low (<300)"

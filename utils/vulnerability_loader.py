"""
Vulnerability data loading and processing utilities.
Provides STH (Students in Temporary Housing) and ENI (Economic Need Index) as separate indicators.

Data Source: Google Sheets (NYC Schools Reference Data)
"""
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)

# Google Sheets configuration for reference data
REFERENCE_SHEET_ID = "1tt-rYw5Z9iPHrJwn7YcagMcX1WvwHEWjhtPapuaUDFE"
REFERENCE_TABS = {
    'eni': 'ENI_by_School',
    'sth': 'STH_by_School',
}

# Threshold for "high" designation (can be adjusted)
HIGH_STH_THRESHOLD = 0.30  # 30% STH is notably high
HIGH_ENI_THRESHOLD = 0.85  # 85% ENI is notably high


def load_vulnerability_data(data_dir: Optional[Path] = None) -> pd.DataFrame:
    """
    Load vulnerability data from Google Sheets (NYC Schools Reference Data).

    Fetches ENI and STH data from separate tabs and merges them.

    Returns DataFrame with:
    - school_dbn: Primary key
    - sth_percent: Students in Temporary Housing percentage
    - economic_need_index: DOE Economic Need Index
    """
    # Import here to avoid circular imports
    from .data_loader import load_from_google_sheets

    try:
        # Load ENI data
        eni_df = load_from_google_sheets(
            sheet_id=REFERENCE_SHEET_ID,
            sheet_name=REFERENCE_TABS['eni']
        )
        logger.info(f"Loaded {len(eni_df)} ENI records from Google Sheets")

        # Load STH data
        sth_df = load_from_google_sheets(
            sheet_id=REFERENCE_SHEET_ID,
            sheet_name=REFERENCE_TABS['sth']
        )
        logger.info(f"Loaded {len(sth_df)} STH records from Google Sheets")

        # Merge ENI and STH data on school_dbn
        df = pd.merge(
            eni_df[['school_dbn', 'economic_need_index']],
            sth_df[['school_dbn', 'sth_count', 'sth_percent']],
            on='school_dbn',
            how='outer'
        )

        # Ensure numeric types
        df['economic_need_index'] = pd.to_numeric(df['economic_need_index'], errors='coerce')
        df['sth_percent'] = pd.to_numeric(df['sth_percent'], errors='coerce')
        df['sth_count'] = pd.to_numeric(df['sth_count'], errors='coerce')

        # Normalize percentages to decimal form (0-1 range)
        # NYC Open Data stores these as whole percentages (e.g., 10.55 for 10.55%)
        # We need decimals (e.g., 0.1055) for proper :.1% formatting in display
        # Version: 2 (force cache refresh)
        sth_max = df['sth_percent'].dropna().max() if len(df['sth_percent'].dropna()) > 0 else 0
        eni_max = df['economic_need_index'].dropna().max() if len(df['economic_need_index'].dropna()) > 0 else 0

        logger.info(f"STH max before normalization: {sth_max}")
        logger.info(f"ENI max before normalization: {eni_max}")

        if sth_max > 1:
            df['sth_percent'] = df['sth_percent'] / 100
            logger.info("Normalized STH percent from whole percentage to decimal")
        if eni_max > 1:
            df['economic_need_index'] = df['economic_need_index'] / 100
            logger.info("Normalized ENI from whole percentage to decimal")

        logger.info(f"Merged vulnerability data: {len(df)} schools")
        return df

    except Exception as e:
        logger.warning(f"Failed to load vulnerability data from Google Sheets: {e}")
        # Return empty DataFrame with expected columns
        return pd.DataFrame(columns=[
            'school_dbn', 'sth_count', 'sth_percent', 'economic_need_index'
        ])


def merge_vulnerability_with_training(
    training_df: pd.DataFrame,
    vulnerability_df: pd.DataFrame
) -> pd.DataFrame:
    """
    Merge vulnerability data with training status data.

    Args:
        training_df: School training status DataFrame (must have 'school_dbn')
        vulnerability_df: Vulnerability data DataFrame

    Returns:
        Merged DataFrame with STH and ENI columns added
    """
    merge_cols = ['school_dbn']
    if 'sth_percent' in vulnerability_df.columns:
        merge_cols.append('sth_percent')
    if 'economic_need_index' in vulnerability_df.columns:
        merge_cols.append('economic_need_index')

    merged = pd.merge(
        training_df,
        vulnerability_df[merge_cols],
        on='school_dbn',
        how='left'
    )

    # Add flag columns for high STH and high ENI
    if 'sth_percent' in merged.columns:
        merged['high_sth'] = merged['sth_percent'] >= HIGH_STH_THRESHOLD

    if 'economic_need_index' in merged.columns:
        merged['high_eni'] = merged['economic_need_index'] >= HIGH_ENI_THRESHOLD

    return merged


def calculate_vulnerability_stats(df: pd.DataFrame) -> dict:
    """
    Calculate summary statistics for vulnerability indicators.

    Args:
        df: DataFrame with vulnerability columns

    Returns:
        Dictionary of statistics
    """
    stats = {
        'total_schools': len(df),
    }

    # STH statistics
    if 'sth_percent' in df.columns:
        sth_data = df['sth_percent'].dropna()
        stats['schools_with_sth_data'] = len(sth_data)
        stats['avg_sth_percent'] = sth_data.mean() if len(sth_data) > 0 else None
        stats['max_sth_percent'] = sth_data.max() if len(sth_data) > 0 else None
        stats['high_sth_count'] = (df['sth_percent'] >= HIGH_STH_THRESHOLD).sum()

    # ENI statistics
    if 'economic_need_index' in df.columns:
        eni_data = df['economic_need_index'].dropna()
        stats['schools_with_eni_data'] = len(eni_data)
        stats['avg_eni'] = eni_data.mean() if len(eni_data) > 0 else None
        stats['max_eni'] = eni_data.max() if len(eni_data) > 0 else None
        stats['high_eni_count'] = (df['economic_need_index'] >= HIGH_ENI_THRESHOLD).sum()

    return stats


def get_sth_color(sth_percent: Optional[float]) -> list:
    """
    Get color for STH percentage visualization.
    Gradient from green (low) to red (high STH).

    Returns RGBA color as list [R, G, B, A].
    """
    if sth_percent is None or pd.isna(sth_percent):
        return [128, 128, 128, 150]  # Gray for unknown

    # Clamp to 0-1
    sth = max(0, min(1, sth_percent))

    # Color gradient based on STH severity
    if sth < 0.10:
        return [100, 160, 120, 180]  # Low - sage green
    elif sth < 0.20:
        return [180, 180, 100, 180]  # Moderate - yellow
    elif sth < 0.30:
        return [200, 150, 80, 180]   # Elevated - amber
    else:
        return [180, 100, 100, 180]  # High - coral/red


# STH tier labels for display
def get_sth_tier(sth_percent: Optional[float]) -> str:
    """Categorize STH percentage into tiers."""
    if sth_percent is None or pd.isna(sth_percent):
        return "Unknown"
    if sth_percent >= 0.30:
        return "High (30%+)"
    elif sth_percent >= 0.20:
        return "Elevated (20-30%)"
    elif sth_percent >= 0.10:
        return "Moderate (10-20%)"
    else:
        return "Low (<10%)"
